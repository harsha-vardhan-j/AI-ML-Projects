{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QZjx03reMU5"
   },
   "source": [
    "#Import the required libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnJIz-w6TQtG",
    "outputId": "f22ccae6-f7c6-4876-e2f4-66642dde4722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/site-packages (3.17.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in ./.local/lib/python3.10/site-packages (0.0.20)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=0.3.75 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/site-packages (from langchain-community) (1.4.20)\n",
      "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/site-packages (from langchain-community) (3.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/site-packages (from langchain-community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.30-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.10/site-packages (from langchain-community) (1.26.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.local/lib/python3.10/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.10/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (0.25.2)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.32.5->langchain-community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.32.5->langchain-community) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.32.5->langchain-community) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (0.4.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.2.0)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.30-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m611.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: requests, httpx-sse, dataclasses-json, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.87\n",
      "    Uninstalling langsmith-0.0.87:\n",
      "      Successfully uninstalled langsmith-0.0.87\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.23\n",
      "    Uninstalling langchain-core-0.1.23:\n",
      "      Successfully uninstalled langchain-core-0.1.23\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.20\n",
      "    Uninstalling langchain-community-0.0.20:\n",
      "      Successfully uninstalled langchain-community-0.0.20\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.0.6 requires langchain-core<0.2,>=0.1.16, but you have langchain-core 0.3.76 which is incompatible.\n",
      "pennylane 0.32.0 requires numpy<1.24, but you have numpy 1.26.2 which is incompatible.\n",
      "panel 0.12.7 requires setuptools<61,>=42, but you have setuptools 69.0.2 which is incompatible.\n",
      "spacy 3.5.1 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.11.7 which is incompatible.\n",
      "spacy 3.5.1 requires typer<0.8.0,>=0.3.0, but you have typer 0.9.0 which is incompatible.\n",
      "tensorboard 2.13.0 requires google-auth-oauthlib<1.1,>=0.5, but you have google-auth-oauthlib 1.1.0 which is incompatible.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.2 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.15.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires absl-py==1.*,>=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires scipy~=1.9.3, but you have scipy 1.11.4 which is incompatible.\n",
      "tensorflow-federated 0.63.0 requires typing-extensions==4.5.*,>=4.5.0, but you have typing-extensions 4.15.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires absl-py==1.*,>=1.0, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires packaging~=22.0, but you have packaging 23.2 which is incompatible.\n",
      "tensorflow-privacy 0.8.11 requires pandas~=1.4, but you have pandas 2.1.3 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.2 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.1.3 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.11.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-0.3.27 langchain-community-0.3.29 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.30 pydantic-settings-2.10.1 requests-2.32.5\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in ./.local/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.local/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/site-packages (4.7.1)\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.47.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/site-packages (from gradio) (3.7.1)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.117.1-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Collecting gradio-client==1.13.2 (from gradio)\n",
      "  Downloading gradio_client-1.13.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.10/site-packages (from gradio) (0.25.2)\n",
      "Collecting huggingface-hub<1.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from gradio) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in ./.local/lib/python3.10/site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in ./.local/lib/python3.10/site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./.local/lib/python3.10/site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.24.0.post1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from gradio-client==1.13.2->gradio) (2023.10.0)\n",
      "Collecting websockets<16.0,>=13.0 (from gradio-client==1.13.2->gradio)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.66.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.33.5->gradio)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.local/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (1.26.18)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.1)\n",
      "Downloading gradio-5.47.0-py3-none-any.whl (60.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.13.2-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.117.1-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m609.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: brotli, websockets, ruff, python-multipart, hf-xet, groovy, starlette, huggingface-hub, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "\u001b[33m  WARNING: The script websockets is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts hf, huggingface-cli and tiny-agents are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script typer is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script fastapi is installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/voc/work/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.5.1 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.11.7 which is incompatible.\n",
      "spacy 3.5.1 requires typer<0.8.0,>=0.3.0, but you have typer 0.19.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed brotli-1.1.0 fastapi-0.117.1 gradio-5.47.0 gradio-client-1.13.2 groovy-0.1.2 hf-xet-1.1.10 huggingface-hub-0.35.1 python-multipart-0.0.20 ruff-0.13.1 safehttpx-0.1.6 starlette-0.48.0 typer-0.19.2 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu\n",
    "!pip install pypdf\n",
    "!pip install -U langchain-community\n",
    "!pip install tiktoken\n",
    "!pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jddSFp3j_hAs"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import openai\n",
    "import os\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUCYUMnLgvJ5"
   },
   "source": [
    "# Loading Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9S0HlZhW_ofN"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('https://www.nestle.com/sites/default/files/asset-library/documents/jobs/the_nestle_hr_policy_pdf_2012.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH5NQqp_in_T"
   },
   "source": [
    " # Creating Vector Representation of Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_5bY_6TK_yFC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/1191152576.py:6: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# Splitting documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Generating embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Using FAISS as the vector database\n",
    "vectordb = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P-uAfytzUA0z"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2CP1tCAiyTS"
   },
   "source": [
    "# Setting Up Question-Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKMZGJeWi17S",
    "outputId": "5076087d-5fa3-4055-d3e3-9ea307d96646"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/3946707704.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n"
     ]
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVU8cmrSi6Da"
   },
   "source": [
    "# Defining Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M4CETG52_0yR"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define the prompt template in English\n",
    "template = \"\"\"\n",
    "I am a HR helpful assistant. Please answer the following question in English.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create the PromptTemplate instance with the modified English template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_cvll7ZVaII",
    "outputId": "04ade9da-56af-4c91-95b1-251f024717b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am a HR helpful assistant. Please answer the following question in English.\n",
      "Question: What are the best practices for conducting interviews?\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_question = \"What are the best practices for conducting interviews?\"\n",
    "formatted_prompt = prompt.format(question=example_question)\n",
    "\n",
    "# Print the result to see the formatted prompt\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wPsztWWVjJe",
    "outputId": "71facd08-89ed-42f7-8663-ced9b6515e87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/990803728.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
      "/tmp/ipykernel_116/990803728.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm_chain.run(question=example_question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several best practices for conducting interviews, including:\n",
      "\n",
      "1. Prepare for the interview by reviewing the candidate's resume and job description.\n",
      "2. Create a structured interview process with a set list of questions.\n",
      "3. Be mindful of the candidate's time and schedule the interview at a convenient time for them.\n",
      "4. Create a welcoming and professional atmosphere for the interview.\n",
      "5. Ask open-ended questions to encourage the candidate to provide detailed responses.\n",
      "6. Listen actively and take notes during the interview.\n",
      "7. Avoid asking illegal or discriminatory questions.\n",
      "8. Provide the candidate with information about the company and the role.\n",
      "9. Allow the candidate to ask questions about the role and company.\n",
      "10. Follow up with the candidate after the interview to provide feedback and next steps.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain  # Import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI # Import ChatOpenAI\n",
    "\n",
    "# Use ChatOpenAI for chat models instead of OpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Create the LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Example usage\n",
    "example_question = \"What are the best practices for conducting interviews?\"\n",
    "response = llm_chain.run(question=example_question)\n",
    "\n",
    "# Print the result\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APP-VcVNjG6C"
   },
   "source": [
    "#  Building Chat Interface with Gradio and Launching the Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WCC_MMuW36N",
    "outputId": "29062bb6-aa81-487e-aa6d-f9a34c950cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1. Prepare thoroughly: Review the candidate's resume and job description, and prepare a list of relevant questions.\n",
      "\n",
      "2. Create a comfortable environment: Ensure the interview room is quiet, well-lit, and free from distractions.\n",
      "\n",
      "3. Use a structured interview format: Ask each candidate the same set of questions to ensure consistency and fairness.\n",
      "\n",
      "4. Listen actively: Pay attention to the candidate's responses and ask follow-up questions to gather more information.\n",
      "\n",
      "5. Take notes: Document key points from the interview to help with decision-making later on.\n",
      "\n",
      "6. Be respectful and professional: Treat all candidates with courtesy and respect, regardless of their qualifications.\n",
      "\n",
      "7. Provide clear information: Explain the next steps in the hiring process and answer any questions the candidate may have.\n",
      "\n",
      "8. Follow up promptly: Contact all candidates to inform them of the hiring decision, whether they were successful or not.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Test code\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"I am a helpful HR assistant. Answer in English. Question: {question} Answer:\",\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Test with a sample question\n",
    "response = llm_chain.run(question=\"What are the best practices for conducting interviews?\")\n",
    "print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "1UjfwNU8can9",
    "outputId": "dd3ac769-4cf1-4b2a-b287-4d1c9dab03cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2410043725.py:52: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(value=[], label=\"Chat with LangChain\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://59c7176f74253726c5.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://59c7176f74253726c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: Hi\n",
      "LangChain response: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set OpenAI API Key\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "I am a helpful assistant. Please answer the following question in English.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "\n",
    "# Initialize ChatOpenAI and LLMChain\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Gradio bot function\n",
    "def bot(history):\n",
    "    try:\n",
    "        # Ensure history is initialized\n",
    "        if not history:\n",
    "            history = []\n",
    "\n",
    "        # Get the user's query\n",
    "        query = history[-1][0]  # Last user input\n",
    "        print(f\"User query: {query}\")  # Debug log\n",
    "\n",
    "        # Send the query to LangChain's LLMChain\n",
    "        response = llm_chain.run(question=query)\n",
    "        print(f\"LangChain response: {response}\")  # Debug log\n",
    "\n",
    "        # Update chatbot history with the response\n",
    "        history[-1] = (query, response)\n",
    "        return history\n",
    "#end of try:\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "        # Update chatbot history with an error message\n",
    "        if history:\n",
    "            history[-1] = (history[-1][0], \"An error occurred. Please try again later.\")\n",
    "        return history or [(\"Error\", \"An unexpected error occurred. Please try again later.\")]\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(value=[], label=\"Chat with LangChain\")\n",
    "    txt = gr.Textbox(show_label=False, placeholder=\"Type your question here...\")\n",
    "\n",
    "    txt.submit(\n",
    "        lambda history, text: (history + [(text, None)], \"\"),  # Append user input\n",
    "        [chatbot, txt],\n",
    "        [chatbot, txt],\n",
    "    ).then(bot, chatbot, chatbot)\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwsNEBSvdObf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
